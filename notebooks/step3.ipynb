{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = train.sample(n=100000)\n",
    "\n",
    "y = np.log( df_train['loss'].values )\n",
    "sparse_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cats = [f for f in df_train.columns if 'cat' in f]\n",
    "for feat in feat_cats:\n",
    "    dummy = pd.get_dummies(df_train[feat].astype('category'))\n",
    "    tmp = csr_matrix(dummy)\n",
    "    sparse_data.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_num = [f for f in df_train.columns if 'cont' in f]\n",
    "scaler = StandardScaler()\n",
    "tmp = csr_matrix(scaler.fit_transform(df_train[f_num]))\n",
    "sparse_data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100000x1093 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 13000000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = hstack(sparse_data, format = 'csr')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_model(input_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(400, input_dim = input_dim, kernel_initializer='he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.45))\n",
    "\n",
    "    model.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer = 'he_normal'))\n",
    "    model.compile(loss = 'mae', optimizer = 'adadelta')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    #chenglong code for fiting from generator (https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "        \n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "            \n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      " - 13s - loss: 7.4744 - val_loss: 7.3758\n",
      "Epoch 2/4\n",
      " - 6s - loss: 6.6436 - val_loss: 5.7869\n",
      "Epoch 3/4\n",
      " - 6s - loss: 4.0099 - val_loss: 1.1226\n",
      "Epoch 4/4\n",
      " - 7s - loss: 1.5846 - val_loss: 0.8870\n",
      "Fold1, score=1947.955792789534\n",
      "Epoch 1/4\n",
      " - 9s - loss: 7.4461 - val_loss: 7.2601\n",
      "Epoch 2/4\n",
      " - 6s - loss: 6.5694 - val_loss: 5.9520\n",
      "Epoch 3/4\n",
      " - 6s - loss: 3.2359 - val_loss: 0.8985\n",
      "Epoch 4/4\n",
      " - 6s - loss: 1.4756 - val_loss: 0.7073\n",
      "Fold2, score=1734.5036701510905\n",
      "Epoch 1/4\n",
      " - 10s - loss: 7.4502 - val_loss: 7.0844\n",
      "Epoch 2/4\n",
      " - 6s - loss: 6.0419 - val_loss: 2.6340\n",
      "Epoch 3/4\n",
      " - 7s - loss: 1.9154 - val_loss: 1.1916\n",
      "Epoch 4/4\n",
      " - 7s - loss: 1.5568 - val_loss: 0.9011\n",
      "Fold3, score=1952.923450412031\n"
     ]
    }
   ],
   "source": [
    "nepochs = 4\n",
    "nfolds = 3\n",
    "\n",
    "cv = KFold(n_splits=nfolds, shuffle = True, random_state = 2018)\n",
    "\n",
    "scores = []\n",
    "for num_iter, (train_index, test_index) in enumerate(cv.split(y)):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test   = X[test_index], y[test_index]\n",
    "        \n",
    "    model = nn_model(X_train.shape[1])\n",
    "\n",
    "    model.fit_generator(generator = batch_generator(X_train, y_train, 128, True),\n",
    "                                  epochs = nepochs,\n",
    "                                  steps_per_epoch = 100,\n",
    "                                  validation_data=(X_test.todense(), y_test),\n",
    "                                  validation_steps=62.5,\n",
    "                                  verbose = 2) \n",
    "    \n",
    "    y_pred = np.exp(model.predict_generator(generator = batch_generatorp(X_test, 128, False), steps = X_test.shape[0])[:,0])\n",
    "\n",
    "    score = mean_absolute_error(np.exp(y_test), y_pred)\n",
    "    print(\"Fold{0}, score={1}\".format(num_iter+1, score))\n",
    "    scores.append(score)\n",
    "    \n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What next?\n",
    "\n",
    "## [Blending](https://mlwave.com/kaggle-ensembling-guide/) & [Stacking](http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/)\n",
    "\n",
    "![](../images/stacking.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
